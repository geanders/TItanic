{
    "contents" : "---\ntitle: \"Naive Bayes model\"\nauthor: \"Brooke Anderson\"\ndate: \"January 20, 2016\"\noutput: html_document\n---\n\n```{r echo = FALSE, message = FALSE}\nlibrary(knitr)\nopts_knit$set(fig.path = '../figures/naive_bayes-')\n```\n\nLoad required libraries.\n\n```{r message = FALSE}\nlibrary(dplyr) ## Data wrangling\nlibrary(e1071) ## Includes `naiveBayes` function\nlibrary(ggplot2) \nlibrary(stringr) ## Helps with regular expression\n```\n\nRead in the data. (I have it in the subdirectory `data` of the parent directory- `..`-- of my current working directory.) Sometimes, some of the machine learning functions can be particularly fussy about class type for variables, so I used `mutate` to specify those for any problem ones. It doesn't hurt to make sure the all the factor variables end up with the same levels and saved order of levels after reading in the data. \n\n```{r}\ntrain <- read.csv(\"../data/train.csv\") %>%\n  mutate(Survived = factor(Survived),\n         Pclass = factor(Pclass),\n         Name = as.character(Name),\n         Sex = factor(Sex))\ntest <- read.csv(\"../data/test.csv\") %>%\n  mutate(Pclass = factor(Pclass),\n         Name = as.character(Name),\n         Sex = factor(Sex))\n\n# Look through columns besides code about survival.\nfor(column in c(\"Pclass\", \"Sex\",\n               \"Ticket\", \"Cabin\", \"Embarked\")){\n  cat(column, \" train levels: \", head(levels(train[ , column]), 5), \"\\n\")\n  cat(column, \" test levels: \", head(levels(test[ , column]), 5), \"\\n\")\n               }\n```\n\nEverything looks fine for `Pclass`, `Sex`, and `Embarked`, but it looks like there will not always be values of all levels of `Ticket` and `Cabin` in both datasets, so we may need to think carefully about thow we use these variables. \n\n## Null model\n\nAs a baseline, you could fit a null model that just takes the most common value of `Survival` and predicts that everyone will have that. Since more people died than survived in the training set-- $P(Y) = `r round(mean(train$Survived == \"1\"), 2)`$ in the training data, where $Y$ is a 0 / 1 indicator of survival--here you would predict that everyone died. \n\nThis model will predict that `Survived` is always 0:\n\n```{r}\npred_train <- rep(0, length = nrow(train))\npred_test <- rep(0, length = nrow(test))\n```\n\nThe accuracy of the `train` dataset is the percent of times, in this case, that `Survived` actually was 0:\n\n```{r}\nmean(train$Survived == \"0\")\n```\n\nTo figure out the accuracy of the predictions from the null model for the `test` data, you need to save a csv with the predictions and submit to Kaggle:\n\n```{r}\nout <- cbind(test$PassengerId, 0)\ncolnames(out) <- c(\"PassengerId\", \"Survived\")\nwrite.csv(out, file = \"../predictions/null_model.csv\", row.names = FALSE)\n```\n\nNow there is a `null_model.csv` file in my `predictions` directory. After submitting to Kaggle, I found the accuracy of this model based on the Public Leaderboard observations was 0.62679.\n\n## Single categorical predictor\n\nFirst, try with a single, categorical predictor, `Pclass`.\n\n```{r}\n# Fit the model-- note same conventions as `glm` formula call\nnb_mod <- naiveBayes(Survived ~ Pclass, data = train)\n```\n\nCheck out the model. It gives you the distribution of the outcome variable (`apriori`; $P(Y)$) and also the probability of each value of `Pclass` conditional on the level of `Survival`: $Pr(X_1 | Y)$ where $X_1$ is the passenger's ticket class and $Y$ is the passenger's survival status.\n\n```{r}\nnb_mod$apriori ## Class distribution for `Survived`\nnb_mod$tables ## Conditional probabilities given of `Pclass` given `Survived`\n```\n\nNote that each row of the `tables` element sums to 1:\n\n```{r}\napply(nb_mod$tables$Pclass, 1, sum)\n```\n\nPredict and assess accuracy within training class:\n\n```{r}\npred_train <- predict(nb_mod, train)\nmean(pred_train == \"1\") ## For a T / F, gives the proportion T's\n```\n\n(If you're having some problems getting `predict` to work with `naiveBayes`, see [here](http://stackoverflow.com/questions/19961441/naivebayes-in-r-cannot-predict-factor0-levels).)\n\nThis model predicts that everyone in First class survives and no one in Second or Third:\n\n```{r}\ntable(pred_train, train$Survived, train$Pclass)\n```\n\nTo determine the accuracy, calculate the percent of time that the predicted value equals the true value for `Survived`:\n\n```{r}\nsum(pred_train == train$Survived) / length(pred_train)\n```\n\nYou can also predict for the `test` data to generate a prediction to submit to Kaggle. \n\n```{r}\npred_test <- predict(nb_mod, test)\nhead(pred_test)\ntable(pred_test)\n```\n\nTo submit, you need to join with the passenger IDs from `test` and write to a csv. I'm saving in a subdirectory of my parent directory called `predictions`. Also, need to convert the factor of `pred_test` results to character then numeric to have it saved properly as 0 / 1.\n\n```{r}\nout <- cbind(test$PassengerId, as.numeric(as.character(pred_test)))\ncolnames(out) <- c(\"PassengerId\", \"Survived\")\nhead(out, 3)\nwrite.csv(out, file = \"../predictions/nb_pclass.csv\", row.names = FALSE)\n```\n\nThis file is now ready to upload to Kaggle. I did, and the accuracy was 0.65550, not too much lower than the testing set accuracy of `r sum(pred_train == train$Survived) / length(pred_train)` for this model. \n\nNote: to find the help file for predicting with `naiveBayes`, use:\n\n```{r eval = FALSE}\n?predict.naiveBayes\n```\n\n## Single continuous predictor\n\nYou can also try Naive Bayes with a continuous varible, like `Age`. \n\n```{r}\nnb_mod <- naiveBayes(Survived ~ Age, data = train)\n```\n\nNow, the \"Conditional probabilities\" part of the model output gives, for each class of `Survived`, the mean (first column) and standard deviations (second column) of the independent variable put into the model (`Age`). \n\n```{r}\nnb_mod\n```\n\nTo visualize, here are density plots for `Age` separated by `Survived`, with red lines showing the mean values given by `nb_mod`: \n\n```{r warning = FALSE, fig.width = 3.5, fig.height = 3}\nvlines <- data.frame(Age = nb_mod$table$Age[ , 1],\n                     Survived = factor(rownames(nb_mod$table$Age)))\n\nggplot(train, aes(Age)) + \n  geom_density() + \n  facet_wrap(~ Survived, ncol = 1) + \n  geom_vline(data = vlines, aes(xintercept = Age), color = \"red\") + \n  theme_minimal()\n```\n\nHere's a comparison of the model output with the means of age calculated by survival, and you can see they're identical.\n\n```{r}\nnb_mod$table$Age\nby(train$Age, train$Survived, mean, na.rm = TRUE)\n```\n\nAgain, you can predict with this model. However, now you have the problem that `Age` is missing for some of your observations. We can talk about strategies for dealing with that-- I'm going to use a very simple approach and replace any of those with the most common value of `Survival` in the dataset, \"0\".\n\n```{r}\npred_train <- predict(nb_mod, train)\npred_train[is.na(pred_train)] <- factor(0)\ntable(pred_train)\n```\n\nThe accuracy in the training data is: \n\n```{r}\nmean(train$Survived == pred_train)\n```\n\nOnly one person is predicted to survive under this model. This happens to be the youngest person on board the ship among the training dataset.\n\n```{r}\ntrain[pred_train == \"1\", ]\nmin(train$Age, na.rm = TRUE)\n```\n\nFit the predictive model to the testing dataset and then try it on Kaggle:\n\n```{r}\npred_test <- predict(nb_mod, test)\npred_test[is.na(pred_test)] <- factor(0)\ntable(pred_test)\n\nout <- cbind(test$PassengerId, as.numeric(as.character(pred_test)))\ncolnames(out) <- c(\"PassengerId\", \"Survived\")\nhead(out, 3)\nwrite.csv(out, file = \"../predictions/nb_age.csv\", row.names = FALSE)\n```\n\nThe accuracy of this model on the Leaderboard was 0.617284, which is worse than that of the null model.\n\n## Multiple predictors\n\nYou can also fit this with multiple predictors. For example, maybe fit a model with `Pclass`, `Sex`, and `Embarked`. Just to keep in mind, although the Naive Bayes model assumes they're all independent of each other, here that's not the case. For example, a much higher percentage of 1st and 2nd class were female then 3rd class:\n\n```{r fig.width = 4, fig.height = 3.5}\nmosaicplot(~ Pclass + Sex, data = train, color = TRUE,\n           main = \"\")\n```\n\nSomething to think about: what are the implications of using Naive Bayes when you violate these assumptions of independence between predictors?\n\nNext, fit the model:\n\n```{r}\n(nb_mod <- naiveBayes(Survived ~ Pclass + Sex + Embarked, data = train))\n```\n\nNow you get separate conditional probabilities for each predictor. Evidently, some values of `Embarked` aren't listed as `NA`s but rather as `\"\"`. They get their own probabilities in `nb_mod`. \n\n```{r}\nsum(is.na(train$Embarked))\nsum(train$Embarked == \"\")\ntrain[train$Embarked == \"\", ]\n```\n\nI think that how we treat these shouldn't affect the Kaggle score, because none of the test observations have `Embarked` equal to `\"\"`.\n\nPredicting this to the training data. Again, if something is missing, I'll replace with \"0\" (better solutions?):\n\n```{r}\npred_train <- predict(nb_mod, train)\npred_train[is.na(pred_train)] <- factor(0)\ntable(pred_train)\nmean(train$Survived == pred_train)\n```\n\nOn the training data, this model has an accuracy of `r mean(train$Survived == pred_train)`, the highest so far by a bit. \n\nTo see how it does on the testing data: \n\n```{r}\npred_test <- predict(nb_mod, test)\npred_test[is.na(pred_test)] <- factor(0)\ntable(pred_test)\n\nout <- cbind(test$PassengerId, as.numeric(as.character(pred_test)))\ncolnames(out) <- c(\"PassengerId\", \"Survived\")\nhead(out, 3)\nwrite.csv(out, file = \"../predictions/nb_class_sex_embark.csv\",\n          row.names = FALSE)\n```\n\nThis model had an accuracy of 0.73684 on the Kaggle Leaderboard data, the best so far. Also, this model had the biggest reduction in accuracy going from the training to the testing data. \n\n## Kitchen sink model\n\nLast, I tried chucking in everything I could think of, incuding some \"engineered\" features. First, some code to add some features: \n\n```{r}\n# Add honorific (Mr., Mrs., Dr., etc.)\nhonorific <- str_extract(train$Name, \",\\\\ .+?\\\\.\") # Uses `stringr` package\nhonorific <- gsub(\"[\\\\,\\\\.\\\\ ]\", \"\", honorific)\nhead(honorific, 3)\ntrain <- cbind(train, honorific)\n\n# Add if age is missing. Note-- this might cover some data leakage--\n# possible that it was easier to find out ages of survivors than victims\ntrain <- mutate(train, \n                 missing = factor(is.na(Age), levels = c(TRUE, FALSE),\n                                  labels = c(\"Age missing\",\n                                             \"Age available\")))\n\n# Mark if they were using a ticket that covered more than 5 people\ncommon_tickets <- names(table(train$Ticket)[table(train$Ticket) > 5])\nhead(common_tickets)\ntrain$common_ticket <- factor(\"0\", levels = c(\"0\", \"1\"))\ntrain$common_ticket[train$Ticket %in% common_tickets] <- \"1\"\ntable(train$common_ticket)\n```\n\nHere are all the variables currently in `train`: \n\n```{r}\nstr(train)\n```\n\nSo I'll fit the model:\n\n```{r}\nkitchen_sink <- naiveBayes(Survived ~ Pclass + Sex + SibSp + \n                             Parch + Fare + Embarked + honorific + \n                             missing , data = train)\nkitchen_sink\n```\n\nPredict on training data:\n\n```{r}\npred_train <- predict(kitchen_sink, train)\npred_train[is.na(pred_train)] <- factor(0)\ntable(pred_train)\nmean(train$Survived == pred_train)\n```\n\nThis accuracy is even better than for the last model, at least for the training dataset.\n\nTo try on the `test` data, I need to add the same new features to that, as well (I'll now use `test` and `train` to figure out the common tickets, though): \n\n```{r}\n# Add honorific (Mr., Mrs., Dr., etc.)\nhonorific <- str_extract(test$Name, \",\\\\ .+?\\\\.\") # Uses `stringr` package\nhonorific <- gsub(\"[\\\\,\\\\.\\\\ ]\", \"\", honorific)\nhead(honorific, 3)\ntest <- cbind(test, honorific)\n\n# Add if age is missing. Note-- this might cover some data leakage--\n# possible that it was easier to find out ages of survivors than victims\ntest <- mutate(test, \n                 missing = factor(is.na(Age), levels = c(TRUE, FALSE),\n                                  labels = c(\"Age missing\",\n                                             \"Age available\")))\n\n# Mark if they were using a ticket that covered more than 5 people\nall_tickets <- c(as.character(train$Ticket), as.character(test$Ticket))\ncommon_tickets <- names(table(all_tickets)[table(all_tickets) > 5])\nhead(common_tickets)\ntest$common_ticket <- factor(\"0\", levels = c(\"0\", \"1\"))\ntest$common_ticket[test$Ticket %in% common_tickets] <- \"1\"\ntable(test$common_ticket)\n```\n\n```{r}\npred_test <- predict(kitchen_sink, test)\npred_test[is.na(pred_test)] <- factor(0)\ntable(pred_test)\n\nout <- cbind(test$PassengerId, as.numeric(as.character(pred_test)))\ncolnames(out) <- c(\"PassengerId\", \"Survived\")\nhead(out, 3)\nwrite.csv(out, file = \"../predictions/nb_kitchen_sink.csv\",\n          row.names = FALSE)\n```\n\nThis model had an accuracy of 0.67464 on the Leaderboard test data, so it was not an improvement over the Naive Bayes with just three predictors.\n\n## Things to think more about\n\n- Laplace smoothing\n- Better to pool predictors with lots of categories into just a few categories?\n- Predicting observations with 1+ feature values missing\n- Way to automate finding the best predictors to include? Overfitting repercussions of trying to automate that?\n- Can violate the assumption of independence between predictors but still be a good model?\n- How does Naive Bayes work if you have a continuous predictor that is not normally distributed? Something really skewed like `Fare` here. Can you set up a Naive Bayes model to use a different distribution for continuous predictors?",
    "created" : 1453329167094.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2764097161",
    "id" : "2DFF83F8",
    "lastKnownWriteTime" : 1453357327,
    "path" : "~/Desktop/MachineLearningClass/Titanic/Rscripts/NaiveBayes.Rmd",
    "project_path" : "Rscripts/NaiveBayes.Rmd",
    "properties" : {
        "tempName" : "Untitled2"
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "type" : "r_markdown"
}